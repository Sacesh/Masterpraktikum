{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YWkUVjVr7qJ"
   },
   "source": [
    "# Retention Time Prediction \n",
    "\n",
    "This notebook is prepared to be run in Google [Colaboratory](https://colab.research.google.com/). In order to train the model faster, please change the runtime of Colab to use Hardware Accelerator, either GPU or TPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3DlTOq3r7qM"
   },
   "source": [
    "This notebook presents a short walkthrough the process of reading a dataset and training a model for retention time prediction. The dataset is an example dataset extracted from a ProteomTools dataset generated in the **Chair of Bioanalytics** at the **School of Life Sciences** at the **Technical University of Munich**.\n",
    "\n",
    "The framework being used is a custom wrapper on top of Keras/TensorFlow. The working name of the package is for now DLOmix -  `dlomix`.\n",
    "\n",
    "This notebook illustrates briefly how to integrate [Weights and Biases](https://wandb.ai/) to track your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aO-69zbKsGey",
    "outputId": "c2064411-9f80-47e6-ca5b-312d547e0f6a",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-06-07T13:09:56.568530200Z",
     "start_time": "2023-06-07T13:09:38.838845400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/wilhelm-lab/dlomix\n",
      "  Cloning https://github.com/wilhelm-lab/dlomix to c:\\users\\micro\\appdata\\local\\temp\\pip-req-build-eoh_r4y1\n",
      "  Resolved https://github.com/wilhelm-lab/dlomix to commit d256a271c9ee411855beb7cf7065b93dbcb11fcf\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dlomix==0.0.4) (3.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dlomix==0.0.4) (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from dlomix==0.0.4) (1.22.4)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from dlomix==0.0.4) (2.12.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dlomix==0.0.4) (0.12.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from dlomix==0.0.4) (6.0.1)\n",
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dlomix==0.0.4) (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->dlomix==0.0.4) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->dlomix==0.0.4) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->dlomix==0.0.4) (5.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->dlomix==0.0.4) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->dlomix==0.0.4) (4.38.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->dlomix==0.0.4) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->dlomix==0.0.4) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->dlomix==0.0.4) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->dlomix==0.0.4) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->dlomix==0.0.4) (2022.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->dlomix==0.0.4) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->dlomix==0.0.4) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->dlomix==0.0.4) (1.2.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow->dlomix==0.0.4) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (4.5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (1.51.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (0.31.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (0.4.8)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (1.14.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (58.1.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (2.12.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (2.12.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (3.8.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (2.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (15.0.6.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (23.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->dlomix==0.0.4) (3.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (0.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (2.2.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (2.16.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (1.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\micro\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow->dlomix==0.0.4) (3.2.2)\n",
      "Building wheels for collected packages: dlomix, fpdf\n",
      "  Building wheel for dlomix (pyproject.toml): started\n",
      "  Building wheel for dlomix (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for dlomix: filename=dlomix-0.0.4-py3-none-any.whl size=38476 sha256=f094071f3f7caeb8275aba87c813713b18979e217a3fce8e2c3849066917368c\n",
      "  Stored in directory: C:\\Users\\micro\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-6utvcfh_\\wheels\\ca\\5f\\e4\\057bee4f859904df09b69e061a64e3d0169172553f5c43982e\n",
      "  Building wheel for fpdf (setup.py): started\n",
      "  Building wheel for fpdf (setup.py): finished with status 'done'\n",
      "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40732 sha256=962fb02d460b00161174441cc3e138353d8392222735b42b7297d5592700262b\n",
      "  Stored in directory: c:\\users\\micro\\appdata\\local\\pip\\cache\\wheels\\44\\35\\8b\\86ce00cec7e4d13c5f189680ae0fa82f919bedc066c2cddae9\n",
      "Successfully built dlomix fpdf\n",
      "Installing collected packages: fpdf, dlomix\n",
      "Successfully installed dlomix-0.0.4 fpdf-1.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/wilhelm-lab/dlomix 'C:\\Users\\micro\\AppData\\Local\\Temp\\pip-req-build-eoh_r4y1'\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\micro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install the DLOmix package in the current environment using pip\n",
    "\n",
    "!python -m pip install git+https://github.com/wilhelm-lab/dlomix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install wandb via pip\n",
    "!python -m pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo7H9qzWr7qN"
   },
   "source": [
    "The available modules in the framework are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0CS0tFur7qN",
    "outputId": "664e0978-980a-4254-90d1-61e9f1603234"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlomix\n",
    "from dlomix import constants, data, eval, layers, models, pipelines, reports, utils\n",
    "print([x for x in dir(dlomix) if not x.startswith(\"_\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsgPZb_Mr7qP"
   },
   "source": [
    "- `constants`: constants to be used in the framework (e.g. Aminoacid alphabet mapping)\n",
    "- `data`:  classes for representing dataset, wrappers around TensorFlow Dataset\n",
    "- `eval`: custom evaluation metrics implemented in Keras/TF to work as `metrics` for model training\n",
    "- `layers`: custom layer implementation required for the different models\n",
    "- `models`: different model implementations for Retention Time Prediction\n",
    "- `pipelines`: complete pipelines to run a task (e.g. Retention Time prediction)\n",
    "- `utils`: helper modules\n",
    "\n",
    "**Note**: reports and pipelines are work-in-progress, some funtionalities are not complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import and Initialize Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb and the Keras Callback\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter project name\n",
    "project_name = 'retention time sample run'\n",
    "wandb.init(project=project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41qXroyKr7qP"
   },
   "source": [
    "## 1. Load Data\n",
    "\n",
    "We can import the dataset class and create an object of type `RetentionTimeDataset`. This object wraps around TensorFlow dataset objects for training+validation or for testing. This can be specified by the arguments `val_ratio` and `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiXz_epEr7qQ"
   },
   "outputs": [],
   "source": [
    "from dlomix.data import RetentionTimeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzNXJ-s6r7qQ"
   },
   "outputs": [],
   "source": [
    "TRAIN_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix/develop/example_dataset/proteomTools_train_val.csv'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "rtdata = RetentionTimeDataset(data_source=TRAIN_DATAPATH,\n",
    "                              seq_length=30, batch_size=BATCH_SIZE, val_ratio=0.2, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UUzvcHGr7qR"
   },
   "source": [
    "Now we have an RT dataset that can be used directly with standard or custom `Keras` models. This wrapper contains the splits we chose when creating it. In our case, they are training and validation splits. To get the TF Dataset, we call the attributes `.train_data` and `.val_data`. The length is now in batches (i.e. `total examples = batch_size x len`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1l6YedCr7qS",
    "outputId": "72576b1a-698d-4632-c398-9e7d1bf8942e"
   },
   "outputs": [],
   "source": [
    " \"Training examples\", BATCH_SIZE * len(rtdata.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEnVWjtRr7qT",
    "outputId": "4a8de4e3-2857-4c6c-d939-c79d72e8313a"
   },
   "outputs": [],
   "source": [
    "\"Validation examples\", BATCH_SIZE * len(rtdata.val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, add config params to wandb.config\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "config.seq_length = 30\n",
    "config.batch_size = BATCH_SIZE\n",
    "config.val_ratio = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWeVi0iar7qT"
   },
   "source": [
    "## 2. Model\n",
    "\n",
    "We can now create the model. We will use a simple Prediction with a conv1D encoder. It has the default working arguments, but most of the parameters can be customized.\n",
    "\n",
    "**Note**: Important is to ensure that the padding length used for the dataset object is equal to the sequence length passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8SGTvfRr7qT"
   },
   "outputs": [],
   "source": [
    "from dlomix.models import RetentionTimePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqrsF6APr7qU"
   },
   "outputs": [],
   "source": [
    "model = RetentionTimePredictor(seq_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adD60VwQr7qU"
   },
   "source": [
    "## 3. Training\n",
    "\n",
    "We can then train the model like a standard Keras model. The training parameters here are from Prosit, but other optimizer parameters can be used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkPIHuWEr7qU"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "from dlomix.eval import TimeDeltaMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLy32wk7r7qU",
    "outputId": "34f9961e-1abc-4f8f-904c-7aac4a404241"
   },
   "outputs": [],
   "source": [
    "# compile the model  with the optimizer and the metrics we want to use, we can add our custom timedelta metric\n",
    "\n",
    "# you can also import tensorflow and build your custom optimizer object and pass it\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse',\n",
    "              metrics=['mean_absolute_error', TimeDeltaMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more parameters to config as per need\n",
    "\n",
    "config.lr = 0.0001\n",
    "config.optimizer = \"adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtEUn_vdr7qV"
   },
   "source": [
    "We store the result of training so that we can explore the metrics and the losses later. We specify the number of epochs for training and pass the training and validation data as previously described.\n",
    "\n",
    "At this point in a script or a notebook, the Callback for WandB is passed to `model.fit()` or similar functions accepting Callbacks (`model.fit_generator()`). \n",
    "\n",
    "Note that the warning is due to the choice of save format for the model, the arguments for the WandbCallback can be passed per preference and need. The documentation for `WandbCallback()` is available here: https://docs.wandb.ai/ref/python/integrations/keras/wandbcallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E14EcoYTr7qV",
    "outputId": "9c88b2d5-e1cb-46b4-e263-73468e222554",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here we pass the WandbCallback to model.fit\n",
    "\n",
    "history = model.fit(rtdata.train_data,\n",
    "                    validation_data=rtdata.val_data,\n",
    "                    epochs=5, callbacks=[WandbCallback()] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oukZ4AyMr7qV"
   },
   "source": [
    "## 3. Testing and Reporting\n",
    "\n",
    "We can create a test dataset to test our model. Additionally, we can use the reporting module to produce plots and evaluate the model.\n",
    "\n",
    "Note: the reporting module is still in progress and some functionalities might easily break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngz4zlnwr7qV"
   },
   "outputs": [],
   "source": [
    "# create the dataset object for test data\n",
    "\n",
    "TEST_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix/develop/example_dataset/proteomTools_test.csv'\n",
    "\n",
    "test_rtdata = RetentionTimeDataset(data_source=TEST_DATAPATH,\n",
    "                              seq_length=30, batch_size=32, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrvR8Cl3r7qV"
   },
   "outputs": [],
   "source": [
    "# use model.predict from keras directly on the testdata\n",
    "\n",
    "predictions = model.predict(test_rtdata.test_data)\n",
    "\n",
    "# we use ravel from numpy to flatten the array (since it comes out as an array of arrays)\n",
    "predictions = predictions.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKk7MD7Wr7qW"
   },
   "outputs": [],
   "source": [
    "# we can get the targets of a specific split to calcualte evaluation metrics against predictions\n",
    "# the get_split_targets function from the RetentionTime dataset does this\n",
    "\n",
    "test_targets = test_rtdata.get_split_targets(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UnLZTZ9r7qW",
    "outputId": "efbf06be-2c80-45c1-de76-ddb38dc14702"
   },
   "outputs": [],
   "source": [
    "test_targets, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kzCh0gwr7qX"
   },
   "outputs": [],
   "source": [
    "from dlomix.reports import RetentionTimeReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7LJZ3TLr7qX"
   },
   "outputs": [],
   "source": [
    "# create a report object by passing the history object and plot different metrics\n",
    "report = RetentionTimeReport(output_path=\"./output\", history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "1iI-_Nufr7qX",
    "outputId": "25baa9f5-1d5b-47ed-d75a-def6a55e43bc"
   },
   "outputs": [],
   "source": [
    "report.plot_keras_metric(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "jt05Xrq6r7qX",
    "outputId": "19e61c3b-2959-4c81-86dd-8bb45a6d4020"
   },
   "outputs": [],
   "source": [
    "report.plot_keras_metric(\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "0GBkd9WSr7qX",
    "outputId": "5055d608-9043-40a0-9735-a34c76964cb4"
   },
   "outputs": [],
   "source": [
    "report.plot_keras_metric(\"timedelta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hABgy_pYr7qY",
    "outputId": "d264236f-9558-4802-fae6-c6a9102892d2"
   },
   "outputs": [],
   "source": [
    "# calculate R2  given the targets and the predictions of the test data\n",
    "report.calculate_r2(test_targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "Tj_33PTbr7qY",
    "outputId": "04f42fd2-0c4c-495f-daa0-e03f69ed7d4d"
   },
   "outputs": [],
   "source": [
    "report.plot_density(test_targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "VnNJJYHsr7qY",
    "outputId": "455ad8b5-167b-4ff9-ba7f-920d88dcc5ab"
   },
   "outputs": [],
   "source": [
    "report.plot_residuals(test_targets, predictions, xrange=(-30, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also produce a complete report with all the relevant plots in one PDF file by calling the `generate_report` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report.generate_report(test_targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1uYK1ZWr7qZ"
   },
   "source": [
    "## 4. Saving and Loading Models\n",
    "\n",
    "Models can be saved normally the same Keras models would be saved. It is better to save the weights and the not the model since it makes it easier and more platform-indepdent when loading the model again. The extra step needed is to create a model object and then load the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnnLsOPVr7qZ"
   },
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "\n",
    "save_path = \"./output/rtmodel\"\n",
    "model.save_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYVNZBd-r7qZ",
    "outputId": "9f3f72f8-f852-46e3-ce04-bc574e4c2b6f"
   },
   "outputs": [],
   "source": [
    "# models can be later loaded by creating a model object and then loading the weights\n",
    "\n",
    "trained_model = RetentionTimePredictor(seq_length=30)\n",
    "trained_model.load_weights(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkUf8vtOr7qZ"
   },
   "source": [
    "We can compare the predictions to make sure that the model was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2ifAmfxr7qZ"
   },
   "outputs": [],
   "source": [
    "new_predictions = trained_model.predict(test_rtdata.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7lPgkKBr7qZ"
   },
   "outputs": [],
   "source": [
    "new_predictions = new_predictions.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifUnCpdAr7qa",
    "outputId": "d1ef7aa7-9eeb-4567-c0a6-628b5440ea19"
   },
   "outputs": [],
   "source": [
    "# confirm all old and new predictions are the same\n",
    "np.allclose(predictions, new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3yrG9l3r7qa"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\"sequence\": test_rtdata.sequences,\n",
    "                           \"irt\": test_rtdata.targets,\n",
    "                           \"predicted_irt\": predictions})\n",
    "\n",
    "results_df.to_csv(\"./output/predictions_irt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"./output/predictions_irt.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Example_RTModel_Walkthrough.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
