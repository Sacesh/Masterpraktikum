{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Playground to implement W&B as well as start hyperparameter-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# WanDB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "#%pip install wandb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T12:48:27.642365200Z",
     "start_time": "2023-07-22T12:48:27.393759500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:27:49.217918800Z",
     "start_time": "2023-07-24T12:27:45.540531800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(['wandb', 'login', '4e8d3dcb1584ad129b3b49ccc34f65b20116ae54'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:43:16.893639100Z",
     "start_time": "2023-07-24T11:43:12.988464200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mnkopp\u001B[0m (\u001B[33mteam-bioinf\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\micro\\OneDrive\\Dokumente\\GitHub\\Masterpraktikum\\wandb\\run-20230724_134321-yp0y5h75</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/yp0y5h75' target=\"_blank\">different-jazz-5</a></strong> to <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction' target=\"_blank\">https://wandb.ai/team-bioinf/precursor_charge_prediction</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/yp0y5h75' target=\"_blank\">https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/yp0y5h75</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/yp0y5h75?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x18008b12f50>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='precursor_charge_prediction')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:43:22.032215700Z",
     "start_time": "2023-07-24T11:43:18.392573500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#%pip install seaborn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:27:49.329036100Z",
     "start_time": "2023-07-24T12:27:49.219920700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset batches + split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import re\n",
    "# the dictionary\n",
    "aa_syntax_dictionary = dict()\n",
    "for index, i in enumerate(list('XACDEFGHIKLMNPQRSTVWY')): # added X for 0 value\n",
    "    aa_syntax_dictionary[i] = index * 100\n",
    "    if i != 'X': # ignore 0 value for X\n",
    "        for count in range(0, 100):\n",
    "            aa_syntax_dictionary[i + \"[UNIMOD:\" + str(count) + \"]\"] = index * 100 + count\n",
    "\n",
    "def seq_translator(sequence, dictionary=aa_syntax_dictionary, print_result=False):\n",
    "    \"\"\"\n",
    "    Translates a sequence into a vector of integers\n",
    "    :param sequence: string\n",
    "    :param dictionary: dictionary\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    pattern = r'[A-Z]\\[[^\\]]*\\]|.' # regex pattern to match amino acids and modifications\n",
    "\n",
    "    result = [match for match in re.findall(pattern, sequence)]\n",
    "\n",
    "    if print_result:\n",
    "        print(result)\n",
    "    # Fill the list with \"X\" characters until it reaches a length of 40\n",
    "    result += ['X'] * (40 - len(result))\n",
    "\n",
    "    return [dictionary[aa] for aa in result]\n",
    "\n",
    "\n",
    "def one_hot_precursor(int_value, charges=[2,3,4]):\n",
    "    \"\"\"\n",
    "    One-hot encodes the precursor charge\n",
    "    :param df: dataframe\n",
    "    :param max_charge_included: int\n",
    "    :return: dataframe\n",
    "    \"\"\"\n",
    "    one_hot = [1 if x == int_value else 0 for x in charges]\n",
    "\n",
    "    return one_hot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:28:59.846285300Z",
     "start_time": "2023-07-24T12:28:59.824238400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'C[UNIMOD:4]', 'L', 'L', 'V', 'A', 'W']\n",
      "[100, 100, 204, 1000, 1000, 1800, 100, 1900, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(seq_translator('AAC[UNIMOD:4]LLVAW', print_result=True))\n",
    "print(one_hot_precursor(2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:29:01.763066700Z",
     "start_time": "2023-07-24T12:29:01.709687700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Thermo_SRM_Pool_meta_data.parquet\n"
     ]
    }
   ],
   "source": [
    "file_list = [\"data/\"+file for file in os.listdir('data') if file.endswith('.parquet')]\n",
    "print(file_list[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:29:03.233567500Z",
     "start_time": "2023-07-24T12:29:03.183919800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### import parquet files, drop all columns we dont need for training, one-hot encode precursor charge, translate sequence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "batches_parquet = dict()\n",
    "for file in file_list:\n",
    "    df = pd.read_parquet(file, engine='fastparquet')\n",
    "    # drop all columns we dont need for training\n",
    "    for column in df.columns:\n",
    "        if column not in [\"modified_sequence\",\"precursor_intensity\", \"precursor_charge\"]:\n",
    "            df.drop(column, axis=1, inplace=True)\n",
    "    charge_ranges = [2, 3, 4] # TODO SET RANGES\n",
    "    df = df[df[\"precursor_charge\"].isin(charge_ranges)] # remove 7+ charge states // only take charge states 2,3,4\n",
    "    df[\"modified_sequence_vector\"] = df[\"modified_sequence\"].apply(seq_translator)\n",
    "    df[\"precursor_charge_vector\"] = df[\"precursor_charge\"].apply(one_hot_precursor, args=(charge_ranges,))\n",
    "    df = df.dropna(subset=['precursor_intensity']) # drop rows with no precursor intensity\n",
    "    batches_parquet[file] = df\n",
    "    break # TODO REMOVE BREAK FOR FIRST FILE IN IN LIST"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:30:15.046123700Z",
     "start_time": "2023-07-24T12:29:05.444039700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "num_classes = len(charge_ranges)\n",
    "class_names = charge_ranges"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:30:15.051675300Z",
     "start_time": "2023-07-24T12:30:15.047125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "      modified_sequence  precursor_charge  precursor_intensity  \\\n0  LPGSLETYVEQEQGENANDR                 2           29525630.0   \n1       HGSLQEYLQNDTGSK                 2           13188580.0   \n2        VEEEEEINSELTAR                 2           20663460.0   \n3  LPGSLETYVEQEQGENANDR                 2           19884630.0   \n4  NSSTAEINETTTSSTDFLAR                 2           12804420.0   \n\n                            modified_sequence_vector precursor_charge_vector  \n0  [1000, 1300, 600, 1600, 1000, 400, 1700, 2000,...               [1, 0, 0]  \n1  [700, 600, 1600, 1000, 1400, 400, 2000, 1000, ...               [1, 0, 0]  \n2  [1800, 400, 400, 400, 400, 400, 800, 1200, 160...               [1, 0, 0]  \n3  [1000, 1300, 600, 1600, 1000, 400, 1700, 2000,...               [1, 0, 0]  \n4  [1200, 1600, 1600, 1700, 100, 400, 800, 1200, ...               [1, 0, 0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>modified_sequence</th>\n      <th>precursor_charge</th>\n      <th>precursor_intensity</th>\n      <th>modified_sequence_vector</th>\n      <th>precursor_charge_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LPGSLETYVEQEQGENANDR</td>\n      <td>2</td>\n      <td>29525630.0</td>\n      <td>[1000, 1300, 600, 1600, 1000, 400, 1700, 2000,...</td>\n      <td>[1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HGSLQEYLQNDTGSK</td>\n      <td>2</td>\n      <td>13188580.0</td>\n      <td>[700, 600, 1600, 1000, 1400, 400, 2000, 1000, ...</td>\n      <td>[1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>VEEEEEINSELTAR</td>\n      <td>2</td>\n      <td>20663460.0</td>\n      <td>[1800, 400, 400, 400, 400, 400, 800, 1200, 160...</td>\n      <td>[1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LPGSLETYVEQEQGENANDR</td>\n      <td>2</td>\n      <td>19884630.0</td>\n      <td>[1000, 1300, 600, 1600, 1000, 400, 1700, 2000,...</td>\n      <td>[1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NSSTAEINETTTSSTDFLAR</td>\n      <td>2</td>\n      <td>12804420.0</td>\n      <td>[1200, 1600, 1600, 1700, 100, 400, 800, 1200, ...</td>\n      <td>[1, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_parquet[file_list[0]].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:45:43.216007Z",
     "start_time": "2023-07-24T11:45:43.188889700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "2    4331294\n3    1523398\n4     115577\nName: precursor_charge, dtype: int64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_parquet[file_list[0]][\"precursor_charge\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:45:46.159015900Z",
     "start_time": "2023-07-24T11:45:46.095514100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-label-dictionary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def multi_label_one_hot_precursor(charge_list, charges_included=[2,3,4]):\n",
    "\n",
    "    one_hot_encoded = [1 if label in charge_list else 0 for label in charges_included]\n",
    "\n",
    "    return one_hot_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:45:48.982207100Z",
     "start_time": "2023-07-24T11:45:48.958161300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "              modified_sequence  \\\n0          AAAASAAEAGIATTGTEGER   \n1         AAAC[UNIMOD:4]FFEQPPR   \n2                    AAADFATHGK   \n3      AAADLMAYC[UNIMOD:4]EAHAK   \n4            AAADSDPNLDPLMNPHIR   \n...                         ...   \n70310           YYVYWYQQLPGTTPK   \n70311            YYYENSDQPIDLTK   \n70312             YYYGHYLDDYHTK   \n70313              YYYSDNFFDGQR   \n70314             YYYVPADFVEYEK   \n\n                                        precursor_charge  \n0      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, ...  \n1      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n2      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n3       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]  \n4                                           [3, 3, 3, 3]  \n...                                                  ...  \n70310         [2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]  \n70311         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]  \n70312  [2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, ...  \n70313  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n70314  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n\n[70315 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>modified_sequence</th>\n      <th>precursor_charge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAAASAAEAGIATTGTEGER</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAAC[UNIMOD:4]FFEQPPR</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAADFATHGK</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAADLMAYC[UNIMOD:4]EAHAK</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAADSDPNLDPLMNPHIR</td>\n      <td>[3, 3, 3, 3]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70310</th>\n      <td>YYVYWYQQLPGTTPK</td>\n      <td>[2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n    </tr>\n    <tr>\n      <th>70311</th>\n      <td>YYYENSDQPIDLTK</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n    </tr>\n    <tr>\n      <th>70312</th>\n      <td>YYYGHYLDDYHTK</td>\n      <td>[2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, ...</td>\n    </tr>\n    <tr>\n      <th>70313</th>\n      <td>YYYSDNFFDGQR</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>70314</th>\n      <td>YYYVPADFVEYEK</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>70315 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping by \"modified_sequence\" and aggregating precursor_charge into a list\n",
    "grouped_df = batches_parquet[file_list[0]].groupby(\"modified_sequence\")[\"precursor_charge\"].agg(list).reset_index()\n",
    "grouped_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:45:52.373993600Z",
     "start_time": "2023-07-24T11:45:50.193380400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "multi_label_df = grouped_df.copy()\n",
    "multi_label_df[\"precursor_charge\"] = grouped_df[\"precursor_charge\"].apply(multi_label_one_hot_precursor)\n",
    "multi_label_df[\"modified_sequence_vector\"] = grouped_df[\"modified_sequence\"].apply(seq_translator)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T07:44:35.263841600Z",
     "start_time": "2023-07-24T07:44:34.826792400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "              modified_sequence precursor_charge  \\\n0          AAAASAAEAGIATTGTEGER        [1, 1, 0]   \n1         AAAC[UNIMOD:4]FFEQPPR        [1, 0, 0]   \n2                    AAADFATHGK        [1, 0, 0]   \n3      AAADLMAYC[UNIMOD:4]EAHAK        [1, 0, 0]   \n4            AAADSDPNLDPLMNPHIR        [0, 1, 0]   \n...                         ...              ...   \n70910           YYVYWYQQLPGTTPK        [1, 1, 0]   \n70911            YYYENSDQPIDLTK        [1, 0, 0]   \n70912             YYYGHYLDDYHTK        [1, 1, 1]   \n70913              YYYSDNFFDGQR        [1, 0, 0]   \n70914             YYYVPADFVEYEK        [1, 0, 0]   \n\n                                modified_sequence_vector  \n0      [100, 100, 100, 100, 1600, 100, 100, 400, 100,...  \n1      [100, 100, 100, 204, 500, 500, 400, 1400, 1300...  \n2      [100, 100, 100, 300, 500, 100, 1700, 700, 600,...  \n3      [100, 100, 100, 300, 1000, 1100, 100, 2000, 20...  \n4      [100, 100, 100, 300, 1600, 300, 1300, 1200, 10...  \n...                                                  ...  \n70910  [2000, 2000, 1800, 2000, 1900, 2000, 1400, 140...  \n70911  [2000, 2000, 2000, 400, 1200, 1600, 300, 1400,...  \n70912  [2000, 2000, 2000, 600, 700, 2000, 1000, 300, ...  \n70913  [2000, 2000, 2000, 1600, 300, 1200, 500, 500, ...  \n70914  [2000, 2000, 2000, 1800, 1300, 100, 300, 500, ...  \n\n[70915 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>modified_sequence</th>\n      <th>precursor_charge</th>\n      <th>modified_sequence_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAAASAAEAGIATTGTEGER</td>\n      <td>[1, 1, 0]</td>\n      <td>[100, 100, 100, 100, 1600, 100, 100, 400, 100,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAAC[UNIMOD:4]FFEQPPR</td>\n      <td>[1, 0, 0]</td>\n      <td>[100, 100, 100, 204, 500, 500, 400, 1400, 1300...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAADFATHGK</td>\n      <td>[1, 0, 0]</td>\n      <td>[100, 100, 100, 300, 500, 100, 1700, 700, 600,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAADLMAYC[UNIMOD:4]EAHAK</td>\n      <td>[1, 0, 0]</td>\n      <td>[100, 100, 100, 300, 1000, 1100, 100, 2000, 20...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAADSDPNLDPLMNPHIR</td>\n      <td>[0, 1, 0]</td>\n      <td>[100, 100, 100, 300, 1600, 300, 1300, 1200, 10...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70910</th>\n      <td>YYVYWYQQLPGTTPK</td>\n      <td>[1, 1, 0]</td>\n      <td>[2000, 2000, 1800, 2000, 1900, 2000, 1400, 140...</td>\n    </tr>\n    <tr>\n      <th>70911</th>\n      <td>YYYENSDQPIDLTK</td>\n      <td>[1, 0, 0]</td>\n      <td>[2000, 2000, 2000, 400, 1200, 1600, 300, 1400,...</td>\n    </tr>\n    <tr>\n      <th>70912</th>\n      <td>YYYGHYLDDYHTK</td>\n      <td>[1, 1, 1]</td>\n      <td>[2000, 2000, 2000, 600, 700, 2000, 1000, 300, ...</td>\n    </tr>\n    <tr>\n      <th>70913</th>\n      <td>YYYSDNFFDGQR</td>\n      <td>[1, 0, 0]</td>\n      <td>[2000, 2000, 2000, 1600, 300, 1200, 500, 500, ...</td>\n    </tr>\n    <tr>\n      <th>70914</th>\n      <td>YYYVPADFVEYEK</td>\n      <td>[1, 0, 0]</td>\n      <td>[2000, 2000, 2000, 1800, 1300, 100, 300, 500, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>70915 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T07:44:36.368611500Z",
     "start_time": "2023-07-24T07:44:36.341081200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### import preprocessed df's"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Make validation data\n",
    "sample_df = batches_parquet[file_list[0]][[\"precursor_charge\", \"modified_sequence_vector\", \"precursor_intensity\"]].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:45:58.962790200Z",
     "start_time": "2023-07-24T11:45:58.785431700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "split_to_columns = True # TODO SET BOOL"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:46:00.869434300Z",
     "start_time": "2023-07-24T11:46:00.831734200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "if split_to_columns:\n",
    "    sample_df[list(range(0, 40))] = pd.DataFrame(sample_df[\"modified_sequence_vector\"].tolist(), index= sample_df.index)\n",
    "    sample_df.drop(\"modified_sequence_vector\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:46:37.807826Z",
     "start_time": "2023-07-24T11:46:02.592450200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "   precursor_charge  precursor_intensity     0     1     2     3     4    5  \\\n0                 2           29525630.0  1000  1300   600  1600  1000  400   \n1                 2           13188580.0   700   600  1600  1000  1400  400   \n2                 2           20663460.0  1800   400   400   400   400  400   \n3                 2           19884630.0  1000  1300   600  1600  1000  400   \n\n      6     7  ...  30  31  32  33  34  35  36  37  38  39  \n0  1700  2000  ...   0   0   0   0   0   0   0   0   0   0  \n1  2000  1000  ...   0   0   0   0   0   0   0   0   0   0  \n2   800  1200  ...   0   0   0   0   0   0   0   0   0   0  \n3  1700  2000  ...   0   0   0   0   0   0   0   0   0   0  \n\n[4 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precursor_charge</th>\n      <th>precursor_intensity</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>29525630.0</td>\n      <td>1000</td>\n      <td>1300</td>\n      <td>600</td>\n      <td>1600</td>\n      <td>1000</td>\n      <td>400</td>\n      <td>1700</td>\n      <td>2000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>13188580.0</td>\n      <td>700</td>\n      <td>600</td>\n      <td>1600</td>\n      <td>1000</td>\n      <td>1400</td>\n      <td>400</td>\n      <td>2000</td>\n      <td>1000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20663460.0</td>\n      <td>1800</td>\n      <td>400</td>\n      <td>400</td>\n      <td>400</td>\n      <td>400</td>\n      <td>400</td>\n      <td>800</td>\n      <td>1200</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>19884630.0</td>\n      <td>1000</td>\n      <td>1300</td>\n      <td>600</td>\n      <td>1600</td>\n      <td>1000</td>\n      <td>400</td>\n      <td>1700</td>\n      <td>2000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head(4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:46:39.030776200Z",
     "start_time": "2023-07-24T11:46:38.999958800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "main_ds = tf.convert_to_tensor(sample_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:46:44.452043800Z",
     "start_time": "2023-07-24T11:46:42.347086500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5970269, 42), dtype=float64, numpy=\narray([[2.000000e+00, 2.952563e+07, 1.000000e+03, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [2.000000e+00, 1.318858e+07, 7.000000e+02, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [2.000000e+00, 2.066346e+07, 1.800000e+03, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       ...,\n       [3.000000e+00, 1.147428e+05, 4.000000e+02, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [3.000000e+00, 1.147428e+05, 4.000000e+02, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [3.000000e+00, 2.021142e+05, 2.000000e+03, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00]])>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:46:45.953989400Z",
     "start_time": "2023-07-24T11:46:45.925583400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = main_ds[:, 0]\n",
    "features = main_ds[:, 1:]\n",
    "\n",
    "# Perform the split\n",
    "train_ds, val_ds, train_ds_labels, val_ds_labels = train_test_split(np.array(features), np.array(target), test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:46:50.242773300Z",
     "start_time": "2023-07-24T11:46:47.796895Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [
    {
     "data": {
      "text/plain": "5970269"
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)+len(val_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:15:45.371877900Z",
     "start_time": "2023-07-24T11:15:45.324191900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [
    {
     "data": {
      "text/plain": "4776215"
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:15:47.129201700Z",
     "start_time": "2023-07-24T11:15:47.068687500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# # Split the data into train, validation, and test sets\n",
    "# X_2 = np.array(sample_df['modified_sequence_vector'].tolist())\n",
    "# y_2 = np.array(sample_df['precursor_charge'])\n",
    "# max_len = max(sample_df.loc[:, 'modified_sequence_vector'].apply(len))  # Find the maximum length\n",
    "#\n",
    "#\n",
    "# # Create an instance of StratifiedShuffleSplit\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "#\n",
    "# # Perform the split\n",
    "# train_val_indices, test_indices = next(sss.split(X_2, y_2))\n",
    "# X_2_train_val, X_2_test = X_2[train_val_indices], X_2[test_indices]\n",
    "# y_2_train_val, y_2_test = y_2[train_val_indices], y_2[test_indices]\n",
    "#\n",
    "# # Create another instance of StratifiedShuffleSplit for train-validation split\n",
    "# sss_train_val = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "#\n",
    "# # Perform the train-validation split\n",
    "# train_indices, val_indices = next(sss_train_val.split(X_2_train_val, y_2_train_val))\n",
    "# X_2_train, X_2_val = X_2_train_val[train_indices], X_2_train_val[val_indices]\n",
    "# y_2_train, y_2_val = y_2_train_val[train_indices], y_2_train_val[val_indices]\n",
    "#\n",
    "# num_classes = 8  # Number of precursor charge classes (1 to 7, plus an extra class for 'None' charge)\n",
    "# y_2_train_encoded = tf.keras.utils.to_categorical(y_2_train, num_classes)\n",
    "# y_2_val_encoded = tf.keras.utils.to_categorical(y_2_val, num_classes)\n",
    "# y_2_test_encoded = tf.keras.utils.to_categorical(y_2_train, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T07:45:30.039899400Z",
     "start_time": "2023-07-24T07:45:04.422621600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KerasTuner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs_kerastuner\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback_kerastuner = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T09:51:44.920265300Z",
     "start_time": "2023-07-24T09:51:44.892748700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[150], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m     model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate), metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m---> 19\u001B[0m tuner \u001B[38;5;241m=\u001B[39m \u001B[43mkeras_tuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRandomSearch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbuild_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobjective\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mval_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43moverwrite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexecutions_per_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdirectory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moutput_tuner\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m tuner\u001B[38;5;241m.\u001B[39msearch(train_ds, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m, validation_data\u001B[38;5;241m=\u001B[39mval_ds, callbacks\u001B[38;5;241m=\u001B[39m[tensorboard_callback_kerastuner, wandb_callback])\n\u001B[0;32m     29\u001B[0m best_model \u001B[38;5;241m=\u001B[39m tuner\u001B[38;5;241m.\u001B[39mget_best_models()[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Lib\\site-packages\\keras_tuner\\tuners\\randomsearch.py:174\u001B[0m, in \u001B[0;36mRandomSearch.__init__\u001B[1;34m(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001B[0m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseed \u001B[38;5;241m=\u001B[39m seed\n\u001B[0;32m    164\u001B[0m oracle \u001B[38;5;241m=\u001B[39m RandomSearchOracle(\n\u001B[0;32m    165\u001B[0m     objective\u001B[38;5;241m=\u001B[39mobjective,\n\u001B[0;32m    166\u001B[0m     max_trials\u001B[38;5;241m=\u001B[39mmax_trials,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    172\u001B[0m     max_consecutive_failed_trials\u001B[38;5;241m=\u001B[39mmax_consecutive_failed_trials,\n\u001B[0;32m    173\u001B[0m )\n\u001B[1;32m--> 174\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moracle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhypermodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Lib\\site-packages\\keras_tuner\\engine\\tuner.py:113\u001B[0m, in \u001B[0;36mTuner.__init__\u001B[1;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hypermodel \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39mrun_trial \u001B[38;5;129;01mis\u001B[39;00m Tuner\u001B[38;5;241m.\u001B[39mrun_trial:\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    107\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived `hypermodel=None`. We only allow not specifying \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    108\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`hypermodel` if the user defines the search space in \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    109\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124musing a `HyperModel` instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    111\u001B[0m     )\n\u001B[1;32m--> 113\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[43m    \u001B[49m\u001B[43moracle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moracle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypermodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhypermodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdirectory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdirectory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproject_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproject_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogger\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[43m    \u001B[49m\u001B[43moverwrite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_model_size \u001B[38;5;241m=\u001B[39m max_model_size\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer \u001B[38;5;241m=\u001B[39m optimizer\n",
      "File \u001B[1;32m~\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:133\u001B[0m, in \u001B[0;36mBaseTuner.__init__\u001B[1;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001B[0m\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreload()\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;66;03m# Only populate initial space if not reloading.\u001B[39;00m\n\u001B[1;32m--> 133\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_populate_initial_space\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# Run in distributed mode.\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dist_utils\u001B[38;5;241m.\u001B[39mis_chief_oracle():\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# Blocks forever.\u001B[39;00m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;66;03m# Avoid import at the top, to avoid inconsistent protobuf versions.\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:204\u001B[0m, in \u001B[0;36mBaseTuner._populate_initial_space\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhypermodel\u001B[38;5;241m.\u001B[39mdeclare_hyperparameters(hp)\n\u001B[0;32m    203\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mupdate_space(hp)\n\u001B[1;32m--> 204\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_activate_all_conditions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:161\u001B[0m, in \u001B[0;36mBaseTuner._activate_all_conditions\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    159\u001B[0m hp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mget_space()\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 161\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhypermodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mupdate_space(hp)\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# Update the recorded scopes.\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[150], line 7\u001B[0m, in \u001B[0;36mbuild_model\u001B[1;34m(hp)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbuild_model\u001B[39m(hp):\n\u001B[0;32m      6\u001B[0m     model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mSequential([\n\u001B[1;32m----> 7\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mEmbedding(input_dim\u001B[38;5;241m=\u001B[39mmax_len, output_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, input_length\u001B[38;5;241m=\u001B[39m\u001B[43mX_2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m),\n\u001B[0;32m      8\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mFlatten(),\n\u001B[0;32m      9\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(units\u001B[38;5;241m=\u001B[39mhp\u001B[38;5;241m.\u001B[39mInt(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdense_1_units\u001B[39m\u001B[38;5;124m'\u001B[39m, min_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, max_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m, step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m),\n\u001B[0;32m     10\u001B[0m                           activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m     11\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(num_classes, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoftmax\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m#hp.Choice('unknown', values=[1, 10])\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     ])\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# Compile the model\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     learning_rate \u001B[38;5;241m=\u001B[39m hp\u001B[38;5;241m.\u001B[39mFloat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m, min_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m, max_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, sampling\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n",
      "\u001B[1;31mIndexError\u001B[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#%pip install keras-tuner\n",
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_len, output_dim=20, input_length=X_2.shape[1]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=hp.Int('dense_1_units', min_value=16, max_value=256, step=8),\n",
    "                          activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    #hp.Choice('unknown', values=[1, 10])\n",
    "    ])\n",
    "    # Compile the model\n",
    "    learning_rate = hp.Float(\"lr\", min_value=0.00001, max_value=0.001, sampling=\"log\"),\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    overwrite=True,\n",
    "    executions_per_trial=3,\n",
    "    directory='output_tuner',)\n",
    "\n",
    "tuner.search(train_ds, epochs=30, validation_data=val_ds, callbacks=[tensorboard_callback_kerastuner, WandbCallback()])\n",
    "\n",
    "best_model = tuner.get_best_models()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T12:55:11.562294Z",
     "start_time": "2023-07-22T12:55:11.480540900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorboard import program\n",
    "\n",
    "tracking_address = \"logs_kerastuner\" # the path of your log file.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tb = program.TensorBoard()\n",
    "    tb.configure(argv=[None, '--logdir', tracking_address])\n",
    "    url = tb.launch()\n",
    "    print(f\"Tensorflow listening on {url}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3., 2., 2., ..., 2., 2., 2.])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:46:55.354494100Z",
     "start_time": "2023-07-24T11:46:55.330307500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train_ds_labels =  np.array([one_hot_precursor(i, charges=charge_ranges) for i in train_ds_labels])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:47:04.641212300Z",
     "start_time": "2023-07-24T11:46:57.398820500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "val_ds_labels = np.array([one_hot_precursor(i, charges=charge_ranges) for i in val_ds_labels])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:47:06.069154500Z",
     "start_time": "2023-07-24T11:47:04.641212300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 0],\n       [1, 0, 0],\n       [1, 0, 0],\n       ...,\n       [1, 0, 0],\n       [1, 0, 0],\n       [1, 0, 0]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:47:06.069154500Z",
     "start_time": "2023-07-24T11:47:06.025132800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "# # hot encoding\n",
    "# train_ds_labels = tf.convert_to_tensor([one_hot_precursor(i) for i in train_ds_labels])\n",
    "# val_ds_labels = tf.convert_to_tensor([one_hot_precursor(i) for i in val_ds_labels])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T10:34:06.234316200Z",
     "start_time": "2023-07-24T10:33:20.484083800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(4776215, 41)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:47:12.520954200Z",
     "start_time": "2023-07-24T11:47:12.499109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.796888e+07, 1.800000e+03, 1.300000e+03, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [8.124313e+05, 4.000000e+02, 1.800000e+03, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [3.148090e+06, 1.000000e+03, 7.000000e+02, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       ...,\n       [1.016920e+07, 1.800000e+03, 1.300000e+03, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [4.015268e+07, 1.800000e+03, 2.040000e+02, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [2.218693e+06, 1.600000e+03, 2.000000e+03, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:47:13.832374300Z",
     "start_time": "2023-07-24T11:47:13.782289200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Define model\n",
    "model_cce = tf.keras.models.Sequential([\n",
    "    #tf.keras.layers.Embedding(input_dim=num_classes, output_dim=8, input_length=train_ds.shape[1]),\n",
    "    #tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=train_ds.shape[1]),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_cce.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:54:54.744453700Z",
     "start_time": "2023-07-24T11:54:54.721529600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel_cce\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Lib\\site-packages\\keras\\engine\\training.py:3229\u001B[0m, in \u001B[0;36mModel.summary\u001B[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001B[0m\n\u001B[0;32m   3198\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Prints a string summary of the network.\u001B[39;00m\n\u001B[0;32m   3199\u001B[0m \n\u001B[0;32m   3200\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3226\u001B[0m \u001B[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001B[39;00m\n\u001B[0;32m   3227\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   3228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuilt:\n\u001B[1;32m-> 3229\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3230\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis model has not yet been built. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3231\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBuild the model first by calling `build()` or by calling \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3232\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe model on a batch of data.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3233\u001B[0m     )\n\u001B[0;32m   3234\u001B[0m layer_utils\u001B[38;5;241m.\u001B[39mprint_summary(\n\u001B[0;32m   3235\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   3236\u001B[0m     line_length\u001B[38;5;241m=\u001B[39mline_length,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3241\u001B[0m     layer_range\u001B[38;5;241m=\u001B[39mlayer_range,\n\u001B[0;32m   3242\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint('precursor_charge_prediction_model_v1/cce_wo7_allSequences.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:54:53.425445900Z",
     "start_time": "2023-07-24T11:54:53.403768900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# X_train, X_test, y_train, y_test\n",
    "history_cce = model_cce.fit(train_ds, train_ds_labels, epochs=30, batch_size=256, validation_data=(val_ds, val_ds_labels), callbacks=[early_stopping, checkpoint_callback, WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T11:54:56.563869500Z",
     "start_time": "2023-07-24T11:54:56.535300200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18658/18658 [==============================] - 34s 2ms/step - loss: 19126.8125 - accuracy: 0.6185 - val_loss: 26600.0820 - val_accuracy: 0.6842\n",
      "Epoch 2/50\n",
      "18658/18658 [==============================] - 33s 2ms/step - loss: 11445.0898 - accuracy: 0.6353 - val_loss: 17460.7207 - val_accuracy: 0.2760\n",
      "Epoch 3/50\n",
      "18658/18658 [==============================] - 32s 2ms/step - loss: 7803.8569 - accuracy: 0.6392 - val_loss: 7226.1621 - val_accuracy: 0.3579\n",
      "Epoch 4/50\n",
      "18658/18658 [==============================] - 33s 2ms/step - loss: 5446.9995 - accuracy: 0.6400 - val_loss: 5186.3994 - val_accuracy: 0.7000\n",
      "Epoch 5/50\n",
      "18658/18658 [==============================] - 32s 2ms/step - loss: 4193.3608 - accuracy: 0.6452 - val_loss: 15039.5850 - val_accuracy: 0.7153\n",
      "Epoch 6/50\n",
      "18639/18658 [============================>.] - ETA: 0s - loss: 2163.0125 - accuracy: 0.6348INFO:tensorflow:Assets written to: C:\\Users\\micro\\OneDrive\\Dokumente\\GitHub\\Masterpraktikum\\wandb\\run-20230724_134321-yp0y5h75\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Adding directory to artifact (C:\\Users\\micro\\OneDrive\\Dokumente\\GitHub\\Masterpraktikum\\wandb\\run-20230724_134321-yp0y5h75\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18658/18658 [==============================] - 33s 2ms/step - loss: 2161.8337 - accuracy: 0.6349 - val_loss: 1573.7461 - val_accuracy: 0.7266\n",
      "Epoch 7/50\n",
      "18648/18658 [============================>.] - ETA: 0s - loss: 135.2842 - accuracy: 0.7173INFO:tensorflow:Assets written to: C:\\Users\\micro\\OneDrive\\Dokumente\\GitHub\\Masterpraktikum\\wandb\\run-20230724_134321-yp0y5h75\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Adding directory to artifact (C:\\Users\\micro\\OneDrive\\Dokumente\\GitHub\\Masterpraktikum\\wandb\\run-20230724_134321-yp0y5h75\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18658/18658 [==============================] - 33s 2ms/step - loss: 135.2186 - accuracy: 0.7173 - val_loss: 0.6600 - val_accuracy: 0.7257\n",
      "Epoch 8/50\n",
      " 2390/18658 [==>...........................] - ETA: 24s - loss: 0.7105 - accuracy: 0.7261"
     ]
    }
   ],
   "source": [
    "# Access the loss, validation loss, and accuracy from the history object\n",
    "loss = history_cce.history['loss']\n",
    "val_loss = history_cce.history['val_loss']\n",
    "accuracy = history_cce.history['accuracy']\n",
    "val_accuracy = history_cce.history['val_accuracy']\n",
    "\n",
    "# Plot the loss, validation loss, and accuracy curves\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Create subplots\n",
    "fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot loss and validation loss\n",
    "ax1.plot(epochs, loss, 'b', label='Training Loss')\n",
    "ax1.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot accuracy and validation accuracy\n",
    "ax2.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:20:32.725626500Z",
     "start_time": "2023-07-24T11:54:59.708255700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check in with Franzi's group for reporting"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multilable Model\n",
    "#### WIP in precursor_charge_predictor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:27:56.122188900Z",
     "start_time": "2023-07-24T12:27:55.994945600Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:28:16.104668900Z",
     "start_time": "2023-07-24T12:28:16.084085900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Testing\n",
    "### check if models only predict charge 2 or also other charges. Due to 'overrepresentation' the best bet for the model could be to only output charge state 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:28:17.283401900Z",
     "start_time": "2023-07-24T12:28:17.212145Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Access the loss, validation loss, and accuracy from the history object\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mhistory_cce\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mloss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      3\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m history_cce\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      4\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m history_cce\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds, batch_size=batch_size)\n",
    "print(\"test loss, test acc:\", results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the models\n",
    "- confusion matrix\n",
    "- accuracy\n",
    "- loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install numpy --upgrade\n",
    "#!pip install pandas --upgrade\n",
    "#!pip install matplotlib --upgrade\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "#do_predictions = model.predict(test_ds)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over the dataset\n",
    "for image_batch, label_batch in test_ds:   # use dataset.unbatch() with repeat\n",
    "   # append true labels\n",
    "   y_true.append(label_batch)\n",
    "   # compute predictions\n",
    "   preds = model.predict(image_batch)\n",
    "   # append predicted labels\n",
    "   y_pred.append(np.argmax(preds, axis = - 1))\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "true_labels = tf.cast(tf.concat([item for item in y_true], axis = 0), tf.float32)\n",
    "predicted_labels = tf.cast(tf.concat([item for item in y_pred], axis = 0), tf.float32)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "#print(cm)\n",
    "report = classification_report(true_labels,predicted_labels, target_names=class_names)\n",
    "\n",
    "report_dict = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "#print(report_dict)\n",
    "print(report)\n",
    "\n",
    "#pd.DataFrame(report_dict).transpose()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:31:08.230628500Z",
     "start_time": "2023-07-24T12:31:08.151444900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy/ Sens/ Spec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:31:25.645324800Z",
     "start_time": "2023-07-24T12:31:25.552652300Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "         precursor_charge                           modified_sequence_vector  \\\n0                       2  [300, 1600, 1800, 600, 400, 800, 1700, 900, 40...   \n1                       2  [300, 1600, 1800, 600, 400, 800, 1700, 900, 40...   \n2                       2  [300, 1600, 1800, 600, 400, 800, 1700, 900, 40...   \n3                       2  [300, 1600, 1800, 600, 400, 800, 1700, 900, 40...   \n4                       2  [300, 1600, 1800, 600, 400, 800, 1700, 900, 40...   \n...                   ...                                                ...   \n2586142                 3  [300, 1800, 1000, 1600, 1200, 204, 400, 500, 1...   \n2586148                 3  [300, 800, 1500, 800, 900, 400, 400, 400, 1300...   \n2586154                 4  [300, 400, 1400, 1800, 100, 1000, 900, 900, 90...   \n2586155                 3  [300, 1300, 300, 1300, 1400, 1300, 1500, 2000,...   \n2586165                 3  [300, 900, 900, 600, 1600, 900, 1200, 500, 170...   \n\n         precursor_intensity  \n0                  7552496.0  \n1                  7674974.0  \n2                  3298128.0  \n3                  1224600.0  \n4                  3298128.0  \n...                      ...  \n2586142           10454540.0  \n2586148            5171662.0  \n2586154           37526080.0  \n2586155            8926203.0  \n2586165             199662.0  \n\n[2409349 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precursor_charge</th>\n      <th>modified_sequence_vector</th>\n      <th>precursor_intensity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>[300, 1600, 1800, 600, 400, 800, 1700, 900, 40...</td>\n      <td>7552496.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[300, 1600, 1800, 600, 400, 800, 1700, 900, 40...</td>\n      <td>7674974.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[300, 1600, 1800, 600, 400, 800, 1700, 900, 40...</td>\n      <td>3298128.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>[300, 1600, 1800, 600, 400, 800, 1700, 900, 40...</td>\n      <td>1224600.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>[300, 1600, 1800, 600, 400, 800, 1700, 900, 40...</td>\n      <td>3298128.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2586142</th>\n      <td>3</td>\n      <td>[300, 1800, 1000, 1600, 1200, 204, 400, 500, 1...</td>\n      <td>10454540.0</td>\n    </tr>\n    <tr>\n      <th>2586148</th>\n      <td>3</td>\n      <td>[300, 800, 1500, 800, 900, 400, 400, 400, 1300...</td>\n      <td>5171662.0</td>\n    </tr>\n    <tr>\n      <th>2586154</th>\n      <td>4</td>\n      <td>[300, 400, 1400, 1800, 100, 1000, 900, 900, 90...</td>\n      <td>37526080.0</td>\n    </tr>\n    <tr>\n      <th>2586155</th>\n      <td>3</td>\n      <td>[300, 1300, 300, 1300, 1400, 1300, 1500, 2000,...</td>\n      <td>8926203.0</td>\n    </tr>\n    <tr>\n      <th>2586165</th>\n      <td>3</td>\n      <td>[300, 900, 900, 600, 1600, 900, 1200, 500, 170...</td>\n      <td>199662.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2409349 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    #print(y_pred.shape, y_true.shape)\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(K.cast(y_pos * y_pred_pos, 'float32'))\n",
    "    tn = K.sum(K.cast(y_neg * y_pred_neg, 'float32'))\n",
    "    fp = K.sum(K.cast(y_neg * y_pred_pos, 'float32'))\n",
    "    fn = K.sum(K.cast(y_pos * y_pred_neg, 'float32'))\n",
    "\n",
    "    print(\"OVERALL:\")\n",
    "    print(\" Accuracy \", ((tp + tn) / (tp + tn + fp + fn)).numpy())\n",
    "    print(\" Sensitivity \", (tp / (tp + fn)).numpy())\n",
    "    print(\" Specificity \", (tn / (tn + fp)).numpy())\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    #print(tp.numpy(), fp.numpy())\n",
    "    test = (((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
    "    #print(test)\n",
    "    denominator = K.sqrt(K.cast(test, 'float32'))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "\n",
    "#print(true_labels, predicted_labels)\n",
    "print(\" matthews_correlation(rounded): \", (matthews_correlation(true_labels, predicted_labels).numpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:31:33.950478700Z",
     "start_time": "2023-07-24T12:31:33.927182800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MCC"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T12:31:59.929377Z",
     "start_time": "2023-07-24T12:31:45.294917300Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m split_to_columns \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;66;03m# TODO SET BOOL\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m split_to_columns:\n\u001B[1;32m----> 3\u001B[0m     \u001B[43minference_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(inference_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodified_sequence_vector\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist(), index\u001B[38;5;241m=\u001B[39m inference_df\u001B[38;5;241m.\u001B[39mindex)\n\u001B[0;32m      4\u001B[0m     inference_df\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodified_sequence_vector\u001B[39m\u001B[38;5;124m\"\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3968\u001B[0m, in \u001B[0;36mDataFrame.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   3966\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setitem_frame(key, value)\n\u001B[0;32m   3967\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, (Series, np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;28mlist\u001B[39m, Index)):\n\u001B[1;32m-> 3968\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setitem_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3969\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, DataFrame):\n\u001B[0;32m   3970\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_item_frame_value(key, value)\n",
      "File \u001B[1;32m~\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4010\u001B[0m, in \u001B[0;36mDataFrame._setitem_array\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4005\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   4006\u001B[0m     \u001B[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001B[39;00m\n\u001B[0;32m   4007\u001B[0m     \u001B[38;5;66;03m#  never try to overwrite values inplace\u001B[39;00m\n\u001B[0;32m   4009\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, DataFrame):\n\u001B[1;32m-> 4010\u001B[0m         \u001B[43mcheck_key_length\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4011\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k1, k2 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(key, value\u001B[38;5;241m.\u001B[39mcolumns):\n\u001B[0;32m   4012\u001B[0m             \u001B[38;5;28mself\u001B[39m[k1] \u001B[38;5;241m=\u001B[39m value[k2]\n",
      "File \u001B[1;32m~\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:401\u001B[0m, in \u001B[0;36mcheck_key_length\u001B[1;34m(columns, key, value)\u001B[0m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m columns\u001B[38;5;241m.\u001B[39mis_unique:\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(value\u001B[38;5;241m.\u001B[39mcolumns) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(key):\n\u001B[1;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumns must be same length as key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;66;03m# Missing keys in columns are represented as -1\u001B[39;00m\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(columns\u001B[38;5;241m.\u001B[39mget_indexer_non_unique(key)[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(value\u001B[38;5;241m.\u001B[39mcolumns):\n",
      "\u001B[1;31mValueError\u001B[0m: Columns must be same length as key"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "print(\"matthews_correlation:\", matthews_corrcoef(true_labels, predicted_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Direct eval:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "eval_prec = Precision()\n",
    "eval_rec = Recall()\n",
    "eval_acc = BinaryAccuracy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for batch in test_ds.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=13, dtype='int')\n",
    "    yhat = model.predict(X)\n",
    "    eval_prec.update_state(y, yhat)\n",
    "    eval_rec.update_state(y, yhat)\n",
    "    eval_acc.update_state(y, yhat)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Precision: {eval_prec.result().numpy()}, Recall: {eval_rec.result().numpy()}, Accuracy: {eval_acc.result().numpy()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
