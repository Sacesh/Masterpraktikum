{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Playground to implement W&B as well as start hyperparameter-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# WanDB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.15.5-py3-none-any.whl (2.1 MB)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.28.1-py2.py3-none-any.whl (214 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from wandb) (6.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting Click!=8.0.0,>=7.1\n",
      "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from wandb) (60.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from wandb) (4.22.1)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp311-cp311-win_amd64.whl (11 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=c34807ad2b4c9a776b8f5db2cd5e4addb3fd01c47196600bc9c68b7ab28e9d63\n",
      "  Stored in directory: c:\\users\\micro\\appdata\\local\\pip\\cache\\wheels\\ea\\b7\\8b\\84e94095ea418b9442f5abeba4ca7b0ad52d3fe7b69d6238a6\n",
      "Successfully built pathtools\n",
      "Installing collected packages: smmap, gitdb, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, Click, appdirs, wandb\n",
      "Successfully installed Click-8.1.6 GitPython-3.1.32 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.28.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 23.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\micro\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#%pip install wandb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:03:44.230358Z",
     "start_time": "2023-07-22T09:03:34.228141200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:05:11.905286Z",
     "start_time": "2023-07-22T09:05:07.204072500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(['wandb', 'login', '4e8d3dcb1584ad129b3b49ccc34f65b20116ae54'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:05:40.903674700Z",
     "start_time": "2023-07-22T09:05:37.396308100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">avid-smoke-1</strong> at: <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/6d7lt1dn' target=\"_blank\">https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/6d7lt1dn</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20230722_110706-6d7lt1dn\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:6d7lt1dn). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c65ac5251c94bc7b762cd7f746782d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\micro\\OneDrive\\Dokumente\\GitHub\\Masterpraktikum\\wandb\\run-20230722_112539-48qk71vs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/48qk71vs' target=\"_blank\">copper-cosmos-2</a></strong> to <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction' target=\"_blank\">https://wandb.ai/team-bioinf/precursor_charge_prediction</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/48qk71vs' target=\"_blank\">https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/48qk71vs</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/48qk71vs?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x20af53b7d90>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:48qk71vs) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.247411â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f617398a958c43498a5ba3cded242d44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">copper-cosmos-2</strong> at: <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/48qk71vs' target=\"_blank\">https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/48qk71vs</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20230722_112539-48qk71vs\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:48qk71vs). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d13bbb4e3b44dc483e24a79241b00c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\micro\\OneDrive\\Dokumente\\GitHub\\Masterpraktikum\\wandb\\run-20230722_112547-6itvdmrq</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/6itvdmrq' target=\"_blank\">logical-music-3</a></strong> to <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction' target=\"_blank\">https://wandb.ai/team-bioinf/precursor_charge_prediction</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/6itvdmrq' target=\"_blank\">https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/6itvdmrq</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/team-bioinf/precursor_charge_prediction/runs/6itvdmrq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x20afdd20e50>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='precursor_charge_prediction')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\micro\\onedrive\\dokumente\\github\\bachelorthesis\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 23.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\micro\\OneDrive\\Dokumente\\GitHub\\BachelorThesis\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#%pip install seaborn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:12:46.275049700Z",
     "start_time": "2023-07-22T09:12:44.130071200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:22:54.433126200Z",
     "start_time": "2023-07-22T11:22:49.234208800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Niklas Dataset batches + split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "import re\n",
    "# the dictionary\n",
    "aa_syntax_dictionary = dict()\n",
    "for index, i in enumerate(list('XACDEFGHIKLMNPQRSTVWY')): # added X for 0 value\n",
    "    aa_syntax_dictionary[i] = index * 100\n",
    "    if i != 'X': # ignore 0 value for X\n",
    "        for count in range(0, 100):\n",
    "            aa_syntax_dictionary[i + \"[UNIMOD:\" + str(count) + \"]\"] = index * 100 + count\n",
    "\n",
    "def seq_translator(sequence, dictionary=aa_syntax_dictionary):\n",
    "    \"\"\"\n",
    "    Translates a sequence into a vector of integers\n",
    "    :param sequence: string\n",
    "    :param dictionary: dictionary\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    pattern = r'[A-Z]\\[[^\\]]*\\]|.' # regex pattern to match amino acids and modifications\n",
    "\n",
    "    result = [match for match in re.findall(pattern, sequence)]\n",
    "\n",
    "\n",
    "    #print(result)\n",
    "    # Fill the list with \"X\" characters until it reaches a length of 40\n",
    "    result += ['X'] * (40 - len(result))\n",
    "\n",
    "    return [dictionary[aa] for aa in result]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:24:02.225026500Z",
     "start_time": "2023-07-22T11:24:02.127250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'C[UNIMOD:4]', 'L', 'L', 'V', 'A', 'W']\n",
      "[100, 100, 204, 1000, 1000, 1800, 100, 1900, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(seq_translator('AAC[UNIMOD:4]LLVAW'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:16:27.741510100Z",
     "start_time": "2023-07-22T11:16:27.694976600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Thermo_SRM_Pool_meta_data.parquet\n"
     ]
    }
   ],
   "source": [
    "file_list = [\"data/\"+file for file in os.listdir('data') if file.endswith('.parquet')]\n",
    "print(file_list[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:22:56.126692200Z",
     "start_time": "2023-07-22T11:22:56.069232900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "batches_parquet = dict()\n",
    "for file in file_list:\n",
    "    df = pd.read_parquet(file, engine='fastparquet')\n",
    "    # drop all columns we dont need for training\n",
    "    for column in df.columns:\n",
    "        if column not in [\"modified_sequence\", \"precursor_charge\"]:\n",
    "            df.drop(column, axis=1, inplace=True)\n",
    "    df[\"modified_sequence\"] = df[\"modified_sequence\"].apply(seq_translator)\n",
    "    batches_parquet[file] = df\n",
    "    # TODO dublicates ?? should be safe because of copy. please validate !"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:30:37.778472400Z",
     "start_time": "2023-07-22T11:24:06.050564100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6080606, 2)\n"
     ]
    }
   ],
   "source": [
    "print(batches_parquet[file_list[0]].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:30:54.426783600Z",
     "start_time": "2023-07-22T11:30:54.401636700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   modified_sequence  precursor_charge\n0  [1000, 1300, 600, 1600, 1000, 400, 1700, 2000,...                 2\n1  [700, 600, 1600, 1000, 1400, 400, 2000, 1000, ...                 2\n2  [1800, 400, 400, 400, 400, 400, 800, 1200, 160...                 2\n3  [1000, 1300, 600, 1600, 1000, 400, 1700, 2000,...                 2\n4  [1200, 1600, 1600, 1700, 100, 400, 800, 1200, ...                 2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>modified_sequence</th>\n      <th>precursor_charge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[1000, 1300, 600, 1600, 1000, 400, 1700, 2000,...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[700, 600, 1600, 1000, 1400, 400, 2000, 1000, ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[1800, 400, 400, 400, 400, 400, 800, 1200, 160...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[1000, 1300, 600, 1600, 1000, 400, 1700, 2000,...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[1200, 1600, 1600, 1700, 100, 400, 800, 1200, ...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_parquet[file_list[0]].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:31:01.436389500Z",
     "start_time": "2023-07-22T11:31:01.371718900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12161212 into shape (32,2,2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[78], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mbatches_parquet\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfile_list\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 12161212 into shape (32,2,2)"
     ]
    }
   ],
   "source": [
    "batches_parquet[file_list[0]].iloc[:].to_numpy().reshape(32, 2, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:32:24.178612100Z",
     "start_time": "2023-07-22T11:32:23.608681400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### import preprocessed df's"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "cce_df = pd.read_csv('testdata/cce.csv')\n",
    "# scce_df = pd.read_csv('testdata/ssce.csv')\n",
    "# multilable_df = pd.read_csv('testdata/multilable.csv') ## WIP"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:13:21.054280700Z",
     "start_time": "2023-07-22T09:13:13.780860900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SCCE / CCE Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dataset-split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "X_2 = np.array(cce_df['sequence_vector'].tolist())\n",
    "y_2 = np.array(cce_df['precursor_charge'])\n",
    "max_len = max(cce_df.loc[:, 'sequence_vector'].apply(len))  # Find the maximum length\n",
    "\n",
    "\n",
    "# Create an instance of StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform the split\n",
    "train_val_indices, test_indices = next(sss.split(X_2, y_2))\n",
    "X_2_train_val, X_2_test = X_2[train_val_indices], X_2[test_indices]\n",
    "y_2_train_val, y_2_test = y_2[train_val_indices], y_2[test_indices]\n",
    "\n",
    "# Create another instance of StratifiedShuffleSplit for train-validation split\n",
    "sss_train_val = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform the train-validation split\n",
    "train_indices, val_indices = next(sss_train_val.split(X_2_train_val, y_2_train_val))\n",
    "X_2_train, X_2_val = X_2_train_val[train_indices], X_2_train_val[val_indices]\n",
    "y_2_train, y_2_val = y_2_train_val[train_indices], y_2_train_val[val_indices]\n",
    "\n",
    "num_classes = 8  # Number of precursor charge classes (1 to 7, plus an extra class for 'None' charge)\n",
    "y_2_train_encoded = tf.keras.utils.to_categorical(y_2_train, num_classes)\n",
    "y_2_val_encoded = tf.keras.utils.to_categorical(y_2_val, num_classes)\n",
    "y_2_test_encoded = tf.keras.utils.to_categorical(y_2_test, num_classes) # TODO war y_2_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:37:42.836675400Z",
     "start_time": "2023-07-22T09:37:33.473309200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(6080604,)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:37:44.577490700Z",
     "start_time": "2023-07-22T09:37:44.562901900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KerasTuner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs_kerastuner\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback_kerastuner = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:37:54.382905200Z",
     "start_time": "2023-07-22T09:37:54.368382700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 27\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[0;32m     19\u001B[0m tuner \u001B[38;5;241m=\u001B[39m keras_tuner\u001B[38;5;241m.\u001B[39mRandomSearch(\n\u001B[0;32m     20\u001B[0m     build_model,\n\u001B[0;32m     21\u001B[0m     objective\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     24\u001B[0m     executions_per_trial\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m     25\u001B[0m     directory\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput_tuner\u001B[39m\u001B[38;5;124m'\u001B[39m,)\n\u001B[1;32m---> 27\u001B[0m tuner\u001B[38;5;241m.\u001B[39msearch(\u001B[43mtrain_ds\u001B[49m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m, validation_data\u001B[38;5;241m=\u001B[39mval_ds, callbacks\u001B[38;5;241m=\u001B[39m[tensorboard_callback_kerastuner, wandb_callback])\n\u001B[0;32m     29\u001B[0m best_model \u001B[38;5;241m=\u001B[39m tuner\u001B[38;5;241m.\u001B[39mget_best_models()[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "#%pip install keras-tuner\n",
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_len, output_dim=20, input_length=X_2.shape[0]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=hp.Int('dense_1_units', min_value=16, max_value=256, step=8),\n",
    "                          activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    #hp.Choice('unknown', values=[1, 10])\n",
    "    ])\n",
    "    # Compile the model\n",
    "    learning_rate = hp.Float(\"lr\", min_value=0.00001, max_value=0.001, sampling=\"log\"),\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    overwrite=True,\n",
    "    executions_per_trial=3,\n",
    "    directory='output_tuner',)\n",
    "\n",
    "tuner.search(train_ds, epochs=30, validation_data=val_ds, callbacks=[tensorboard_callback_kerastuner, wandb_callback])\n",
    "\n",
    "best_model = tuner.get_best_models()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:39:39.648976900Z",
     "start_time": "2023-07-22T09:38:49.146088300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorboard import program\n",
    "\n",
    "tracking_address = \"logs_kerastuner\" # the path of your log file.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tb = program.TensorBoard()\n",
    "    tb.configure(argv=[None, '--logdir', tracking_address])\n",
    "    url = tb.launch()\n",
    "    print(f\"Tensorflow listening on {url}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 30\u001B[0m\n\u001B[0;32m     26\u001B[0m y_2_test_encoded \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mto_categorical(y_2_train, num_classes)\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# Define model\u001B[39;00m\n\u001B[0;32m     29\u001B[0m model_cce \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mSequential([\n\u001B[1;32m---> 30\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mEmbedding(input_dim\u001B[38;5;241m=\u001B[39mmax_len, output_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, input_length\u001B[38;5;241m=\u001B[39m\u001B[43mX_2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m),\n\u001B[0;32m     31\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mFlatten(),\n\u001B[0;32m     32\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m64\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m     33\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(num_classes, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoftmax\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     34\u001B[0m ])\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# Compile the model\u001B[39;00m\n\u001B[0;32m     37\u001B[0m model_cce\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[1;31mIndexError\u001B[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model_cce = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_len, output_dim=20, input_length=X_2.shape[1]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_cce.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint('precursor_charge_prediction_model_v1/cce_wo7_allSequences.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:14:18.791263800Z",
     "start_time": "2023-07-22T09:14:07.445511800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_cce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m history_cce \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_cce\u001B[49m\u001B[38;5;241m.\u001B[39mfit(X_2_train, y_2_train_encoded, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, validation_data\u001B[38;5;241m=\u001B[39m(X_2_val, y_2_val_encoded), callbacks\u001B[38;5;241m=\u001B[39m[checkpoint_callback, early_stopping, wandb_callback]) \u001B[38;5;66;03m#, wandb_callback])\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model_cce' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_cce = model_cce.fit(X_2_train, y_2_train_encoded, epochs=10, batch_size=32, validation_data=(X_2_val, y_2_val_encoded), callbacks=[checkpoint_callback, early_stopping, wandb_callback]) #, wandb_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T09:13:58.604225500Z",
     "start_time": "2023-07-22T09:13:58.591196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Access the loss, validation loss, and accuracy from the history object\n",
    "loss = history_cce.history['loss']\n",
    "val_loss = history_cce.history['val_loss']\n",
    "accuracy = history_cce.history['accuracy']\n",
    "val_accuracy = history_cce.history['val_accuracy']\n",
    "\n",
    "# Plot the loss, validation loss, and accuracy curves\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Create subplots\n",
    "fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot loss and validation loss\n",
    "ax1.plot(epochs, loss, 'b', label='Training Loss')\n",
    "ax1.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot accuracy and validation accuracy\n",
    "ax2.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check in with Franzi's group for reporting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multilable Model\n",
    "#### WIP in precursor_charge_predictor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T07:48:05.671673Z",
     "start_time": "2023-07-21T07:48:05.668128300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Testing\n",
    "### check if models only predict charge 2 or also other charges. Due to 'overrepresentation' the best bet for the model could be to only output charge state 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
