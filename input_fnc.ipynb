{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "File import for .parquet, .tsv and .csv files\n",
    "At the moment a mix of .parquet, .tsv and .csv files will also be combined into one dataframe.\n",
    "\n",
    "Providing a column mapping is optional. If no column mapping is provided, the default mapping will be used \n",
    "\n",
    "input: \n",
    "dir_path: path to the directory containing the files\n",
    "file_types: list of file types to be imported\n",
    "column_mapping: dictionary with column names as keys and the corresponding column names in the files as values\n",
    "\n",
    "defaults: \n",
    "dir_path: 'data/'\n",
    "file_types: ['.parquet', '.tsv', '.csv']\n",
    "columns: {modified_sequence: 'modified_sequence', precursor_charge: 'precursor_charge', precursor_intensity: 'precursor_intensity'}\n",
    "\n",
    "output: \n",
    "df: dataframe containing the imported data\n",
    "'''\n",
    "def combine_files_into_df(dir_path='data/', file_types=['.parquet', '.tsv', '.csv'], column_mapping=None):\n",
    "    dfs = []\n",
    "    \n",
    "    if column_mapping is None:\n",
    "        column_mapping = {\n",
    "            'modified_sequence': 'modified_sequence',\n",
    "            'precursor_charge': 'precursor_charge',\n",
    "            'precursor_intensity': 'precursor_intensity'\n",
    "        }\n",
    "    \n",
    "    for file in os.listdir(dir_path):\n",
    "        if any(file.endswith(file_type) for file_type in file_types):\n",
    "            file_path = os.path.join(dir_path, file)\n",
    "            \n",
    "            if file.endswith('.parquet'):\n",
    "                df = pd.read_parquet(file_path, engine='fastparquet')\n",
    "            elif file.endswith('.tsv'):\n",
    "                df = pd.read_csv(file_path, sep='\\t')\n",
    "            elif file.endswith('.csv'):\n",
    "                df = pd.read_csv(file_path)\n",
    "            else:\n",
    "                raise ValueError(f'File type {file_type} not supported')\n",
    "            \n",
    "            # Rename columns based on the provided mapping\n",
    "            df = df.rename(columns=column_mapping)\n",
    "            dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
